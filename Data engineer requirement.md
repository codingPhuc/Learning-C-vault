- firstly needs to be intriguing enough to have someone click on it in the first place, most projects fail at this point.
    
- Then once someone is inside the project, they need to be convinced that its your work and not some copy pasta. It needs to be very unique and the narrative and problem itself must be genuine.
    
- Then the project itself should demonstrate elements of a professional workplace software project, I.e. coding best practises, containerisation, unit/integration tests, ci/cd, exception handling, solid documentation and requirements (not just one monolith readme), development roadmap. I would say bonus points for the project being dynamic with updates, a purposeful branching strategy and version tagging; no professional project is static. Also collaboration (with friends or making the project OS) could help.
    
- Then it should display solid data engineering elements. Are you tracking metrics for data quality, batch, data validation, performance etc? Infrastructure monitoring? ETL logging? (If someone showed me a dashboard (e.g. grafana) with all of that I would be floored but thats just me).

If you make a library or package that gets popular, then people will know what it is and who you are.


data engineer project : 
https://www.projectpro.io/article/real-world-data-engineering-projects-/472



# data engineer 
Sure, here are the requirements for the Senior Data Engineer position:

1. **Experience with Relational databases or NoSQL databases.**
2. **Mastery of one of Python**, or a similar language.
3. Experience in **large-scale deployment and performance tuning**.
4. **Development experience in Linux system environments**.
5. Experience with **ETL/ELT and integration flows in Airflow** or similar.
6. Knowledge of **data warehousing concepts**.
7. Knowledge of **BI technologies, methodologies**, and their application.
8. Ability to **quickly learn new technologies** and push the envelope for performance and reliability.
9. **Good Docker/Kubernetes knowledge** is a plus.
10. **Strong analytical and problem-solving skills**.

Please note that these are the qualifications you should have to be considered for the role. Itâ€™s also important to remember that demonstrating these skills during the interview process can be just as important as having them on your resume. Good luck! ðŸ˜Š



job 2 

Here are the top 3 reasons to join the company, the job descriptions for different levels, and the skills and experiences required:

**Top 3 Reasons To Join Us**

1. Very attractive starting income
2. Insightful mentorship from Experts & C-level
3. Ownership on international projects

**The Job**

For Fresher/Junior positions:

- The Home Racer Program 2024 is a 6-month immersive experience for passionate fresh graduates and professionals with less than 2-year working experience in Tech, Data, or Product fields.
- Develop, supervise the quality of data pipelines, and implement alerting for analytic & reporting activities.
- Collaborate with cross-functional teams to provide technical solutions and support for data-centric projects.

For middle-level position:

- Analyze and design metrics and dimensions for critical financial reporting processes with different database technology stacks (Oracle, Postgres, Cassandraâ€¦), and different data processing / programming language (Python, Scala, SQLâ€¦)
- Implement and monitor ETL / ELT processes.
- Ensuring data quality criteria are met and implementing reconciliation processes.

**Your Skills and Experience**

For Fresher/Junior positions:

- University graduate with GPA of 3/4 and 7.5/10 with less than 1-year working experience.
- Proficient in English with a level of IELTS 6.5 or equivalent.
- Proficiency in SQL or other programming languages to accelerate your development faster.
- Passion for numbers & data analysis
- Strong logical thinking, problem-solving skills, communication skills & presentation skills to detect the business situation then propose positive changes.

For middle-level position:

- Diploma/bachelorâ€™s degree in IT or relevant fields (preferred)
- 2+ yearsâ€™ experience in ingestion, and transformation of data from streaming or batch processing Airflow, DBT, Kafka, Spark
- Professional experience in coding pipelines using Python or Scala
- Demonstrably deep understanding of SQL and analytical data warehouses.

**Why Youâ€™ll Love Working Here**

- 13th-month Salary and performance- based KPI Bonus
- 15+ Annual Leaves
- Full Social Insurance, 24/7 Accidental Insurance, Annual Medical Check-up
- Team Building and CSR activities: Year-end Party, New-year Party, Company trip, Charity activities, Blood donation
- Learning workshops: Udemy E-learning, English courses, Senior management development training programs


Here are the main responsibilities and requirements for the Data Engineer role:

**Main Responsibilities:**

1. Receiving and understanding business requirements.
2. Examining, analyzing, and evaluating source data.
3. Mapping source data with Data Warehouse.
4. Designing, building, executing, and managing the data extraction process.
5. Designing, building, and executing periodically & Adhoc reports.
6. Comparing & checking data.
7. Handing over source code, jobs to extract data to Operation Department.
8. Joining IT project and performing assigned tasks within the project scope.
9. Performing other tasks assigned by the team leader.

**Requirements:**

**Educational Qualifications:**

1. Graduate majoring related to IT or MIS.

**Relevant Knowledge / Expertise:**

1. Knowledge of banking (products, services, process,â€¦).
2. Knowledge of MIS, Data Warehouse.
3. Knowledge of database management and data mining.
4. Knowledge of Data Model, Dimensional Model.
5. Proficient programming languages: C#, VB.NET, SQL, PL / SQL, Visual Fox.
6. Proficient Database: Oracle, SQL Server, Visual Fox, MS Access.
7. Proficient ETL tools: DataStage, SSIS, ODI, Informatica.
8. Can use Data Modeling tools: Erwin, Power Designer.

**Skills:**

1. Foreign language: English (can read documents and communicate).
2. Skills to use the support software: Microsoft Office, Microsoft Project.
3. Communications Capability.
4. Problem Solving Capability.
5. Skills to collect, filter, analyze and evaluate information.
6. Ability to teamwork.

**Relevant Experiences:**

1. At least 02 years of working experience in banking data processing or related fields in MIS, Data Warehouse.

**Personal Characteristics:**

1. Willing to learn more, adapt quickly to new things.
2. Proactive, hard work, careful, patient, friendly.


job3 
**Skills & Qualifications:**

- Bachelorâ€™s degree in Management Information Systems, Mathematics, Statistics or related fields.
- At least 2 years of experience with modern data stack (Databricks, dbt, Github, Airflow, Fivetran, Power BI).
- Ability to extract, transform, and load data from a wide variety of data sources using SQL, Python, dbt, Spark and AWS technologies.
- Demonstrated skills in analytical thinking, problem-solving, and attention to detail.
- Demonstrated ability to manage time and prioritize projects to meet deadlines.
- Ability to work in big collaborative teams in a dynamic working environment.
- Experience working with business system requirements and building solutions.
- Experience gathering/documenting business requirements, using industry-standard business intelligence tools to extract data, formulate metrics and build reports.
- Experience working with agile concepts.
- Ability to effectively prioritize projects, manage multiple competing priorities simultaneously and drive projects to completion.
- Collaborative and client-centric mindset with excellent written communication and presentation skills.
- English language skills: fluent in reading and writing, comfortable with listening and speaking.

**Responsibilities:**

- Collaborate with team members to collect business requirements, define successful analytics outcomes, and design data models.
- Develop and implement scalable and reliable analytics, tools, KPI dashboards, and metrics that drive decisions.
- Design and implement data quality processes across software systems and highlight opportunities for improvement.
- Work with business stakeholders, gathering requirements and delivering complete data products (datasets, reporting, dashboard, data visualization and more).
- Collaborate with other data analysts, data engineers, and data product teams to implement advanced analytics models.
- Own the design, development, and maintenance of data pipelines.
- Build and implement version control data pipelines, data unit testing as well as continuous integration, continuous delivery (CI/CD).
- Continually improve ongoing reporting and analysis processes by automating or simplifying self-service support for customers.
- Maintain data catalog a scalable resource to support self-service and single-source-of-truth analytics.